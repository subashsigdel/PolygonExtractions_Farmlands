{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222400ed-50b5-45da-a39b-772c4ee4f331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import cv2\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, mapping\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "mask_path = \"outputs/tile_20480_40960_masks.tif\"\n",
    "clean_mask_path = \"masks_clean1.tif\"\n",
    "boundaries_path = \"masks_boundaries1.tif\"\n",
    "polygons_geojson = \"polygons.geojson1\"\n",
    "\n",
    "# --- Watershed Separation (for touching objects) ---\n",
    "USE_WATERSHED_SEPARATION = True  # Separate touching objects using watershed\n",
    "WATERSHED_THRESHOLD = 0.2        # Lower = more aggressive separation (0.1-0.5)\n",
    "\n",
    "# --- Morphological Processing ---\n",
    "USE_MORPHOLOGY = True        # Apply morphological operations to improve shapes\n",
    "MORPH_CLOSE_KERNEL = 2       # Kernel size for closing (fill small holes)\n",
    "MORPH_CLOSE_ITERATIONS = 1   # How many times to apply closing\n",
    "MORPH_DILATE_KERNEL = 3      # Kernel size for dilation (expand objects)\n",
    "MORPH_DILATE_ITERATIONS = 1  # How many times to dilate\n",
    "MORPH_ERODE_KERNEL = 3       # Kernel size for erosion (shrink back slightly)\n",
    "MORPH_ERODE_ITERATIONS = 1   # How many times to erode (use to smooth after dilation)\n",
    "\n",
    "# --- Filtering Parameters ---\n",
    "MIN_AREA = 2000              # Minimum area in pixels (increase to remove smaller blobs)\n",
    "MAX_AREA = 5000000          # Maximum area (remove if too large)\n",
    "\n",
    "# Shape quality filters\n",
    "MIN_COMPACTNESS = 0.01       # Remove irregular shapes (0-1, higher = more compact)\n",
    "MIN_SOLIDITY = 0.2          # Remove fragmented shapes (0-1, area/convex_hull)\n",
    "MAX_ASPECT_RATIO = 200.0      # Remove elongated shapes (width/height ratio)\n",
    "MIN_CONVEXITY = 0.3         # Remove concave/irregular shapes (0-1)\n",
    "MIN_EXTENT = 0.05            # Remove thin/sparse shapes (area/bounding_box)\n",
    "\n",
    "BOUNDARY_THICKNESS = 4      \n",
    "CREATE_BOUNDARY_FILE = True\n",
    "SAVE_GEOJSON = True\n",
    "\n",
    "def load_sam_mask(mask_path):\n",
    "    \"\"\"Load SAM mask and convert to instance mask\"\"\"\n",
    "    with rasterio.open(mask_path) as src:\n",
    "        mask_data = src.read()\n",
    "        profile = src.profile.copy()\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MASK ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Shape: {mask_data.shape}\")\n",
    "    print(f\"Dtype: {mask_data.dtype}\")\n",
    "    print(f\"Bands: {mask_data.shape[0] if mask_data.ndim == 3 else 1}\")\n",
    "    \n",
    "    # Handle multi-band masks\n",
    "    if mask_data.ndim == 3 and mask_data.shape[0] > 1:\n",
    "        print(f\"\\nâœ“ Multi-band mask: {mask_data.shape[0]} bands\")\n",
    "        \n",
    "        instance_mask = np.zeros(mask_data.shape[1:], dtype=np.uint16)\n",
    "        \n",
    "        print(f\"\\nAnalyzing bands:\")\n",
    "        valid_bands = 0\n",
    "        for band_idx in range(mask_data.shape[0]):\n",
    "            band = mask_data[band_idx]\n",
    "            nonzero = np.count_nonzero(band > 0)\n",
    "            \n",
    "            if nonzero > 0:\n",
    "                valid_bands += 1\n",
    "                band_mask = band > 0\n",
    "                instance_mask[band_mask & (instance_mask == 0)] = band_idx + 1\n",
    "                \n",
    "                if band_idx < 10:\n",
    "                    print(f\"  Band {band_idx+1}: {nonzero:,} pixels\")\n",
    "        \n",
    "        if mask_data.shape[0] > 10:\n",
    "            print(f\"  ... and {mask_data.shape[0] - 10} more bands\")\n",
    "        \n",
    "        print(f\"\\nâœ“ Converted {valid_bands} bands\")\n",
    "        \n",
    "    else:\n",
    "        instance_mask = mask_data.squeeze()\n",
    "        unique_vals = np.unique(instance_mask)\n",
    "        unique_vals = unique_vals[unique_vals > 0]\n",
    "        \n",
    "        if len(unique_vals) > 1:\n",
    "            print(f\"\\nâœ“ Single-band instance mask: {len(unique_vals)} objects\")\n",
    "        else:\n",
    "            print(f\"\\nâš  Binary mask - separating connected regions\")\n",
    "            instance_mask, num = ndimage.label(instance_mask > 0)\n",
    "            print(f\"â†’ Found {num} connected regions\")\n",
    "    \n",
    "    num_instances = len(np.unique(instance_mask)) - 1\n",
    "    total_pixels = np.sum(instance_mask > 0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULT: {num_instances} objects, {total_pixels:,} pixels\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return instance_mask, profile, transform, crs\n",
    "\n",
    "def apply_watershed_separation(instance_mask):\n",
    "    \"\"\"\n",
    "    Apply watershed algorithm to separate touching objects\n",
    "    This is useful when SAM detects objects that are touching/overlapping\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    instance_mask : numpy.ndarray\n",
    "        Instance mask where objects might be touching\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray : Instance mask with separated objects\n",
    "    \"\"\"\n",
    "    if not USE_WATERSHED_SEPARATION:\n",
    "        return instance_mask\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"WATERSHED SEPARATION (Separate Touching Objects)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create binary mask of all objects\n",
    "    binary_mask = (instance_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    # Distance transform to find object centers\n",
    "    dist = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 3)\n",
    "    \n",
    "    # Normalize distance\n",
    "    dist_norm = cv2.normalize(dist, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # Find local maxima (object centers) with configurable threshold\n",
    "    _, peaks = cv2.threshold(dist_norm, WATERSHED_THRESHOLD * dist_norm.max(), 255, cv2.THRESH_BINARY)\n",
    "    peaks = peaks.astype(np.uint8)\n",
    "    \n",
    "    # Label the peaks (these become watershed markers)\n",
    "    _, markers = cv2.connectedComponents(peaks)\n",
    "    \n",
    "    # Small dilation of markers to ensure they're inside objects\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    markers = cv2.dilate(markers.astype(np.uint8), kernel, iterations=1)\n",
    "    markers = markers.astype(np.int32)\n",
    "    \n",
    "    # Mark background\n",
    "    markers[binary_mask == 0] = 0\n",
    "    \n",
    "    # Apply watershed\n",
    "    binary_3ch = cv2.cvtColor(binary_mask * 255, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(binary_3ch, markers)\n",
    "    \n",
    "    # Create separated instance mask\n",
    "    # Watershed boundaries are marked as -1, we set them to 0\n",
    "    separated_mask = np.where(markers > 0, markers, 0).astype(np.uint16)\n",
    "    \n",
    "    # Count objects before and after\n",
    "    before_count = len(np.unique(instance_mask)) - 1\n",
    "    after_count = len(np.unique(separated_mask)) - 1\n",
    "    \n",
    "    print(f\"âœ“ Watershed separation applied:\")\n",
    "    print(f\"  Threshold: {WATERSHED_THRESHOLD}\")\n",
    "    print(f\"  Objects before: {before_count}\")\n",
    "    print(f\"  Objects after: {after_count}\")\n",
    "    print(f\"  New objects separated: {after_count - before_count}\")\n",
    "    \n",
    "    return separated_mask\n",
    "\n",
    "def apply_morphological_operations(instance_mask):\n",
    "    \"\"\"\n",
    "    Apply morphological operations to improve object shapes\n",
    "    - Closing: fills small holes and gaps\n",
    "    - Dilation: expands objects, smooths edges\n",
    "    - Erosion: shrinks objects back (optional, for smoothing)\n",
    "    \"\"\"\n",
    "    if not USE_MORPHOLOGY:\n",
    "        return instance_mask\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MORPHOLOGICAL PROCESSING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    improved_mask = np.zeros_like(instance_mask, dtype=np.uint16)\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        \n",
    "        # 1. Morphological Closing (fill small holes and gaps)\n",
    "        if MORPH_CLOSE_KERNEL > 0 and MORPH_CLOSE_ITERATIONS > 0:\n",
    "            close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                                     (MORPH_CLOSE_KERNEL, MORPH_CLOSE_KERNEL))\n",
    "            obj_mask = cv2.morphologyEx(obj_mask, cv2.MORPH_CLOSE, close_kernel, \n",
    "                                       iterations=MORPH_CLOSE_ITERATIONS)\n",
    "        \n",
    "        # 2. Dilation (expand object, smooth edges)\n",
    "        if MORPH_DILATE_KERNEL > 0 and MORPH_DILATE_ITERATIONS > 0:\n",
    "            dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                                      (MORPH_DILATE_KERNEL, MORPH_DILATE_KERNEL))\n",
    "            obj_mask = cv2.dilate(obj_mask, dilate_kernel, iterations=MORPH_DILATE_ITERATIONS)\n",
    "        \n",
    "        # 3. Erosion (shrink back slightly to smooth, optional)\n",
    "        if MORPH_ERODE_KERNEL > 0 and MORPH_ERODE_ITERATIONS > 0:\n",
    "            erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                                     (MORPH_ERODE_KERNEL, MORPH_ERODE_KERNEL))\n",
    "            obj_mask = cv2.erode(obj_mask, erode_kernel, iterations=MORPH_ERODE_ITERATIONS)\n",
    "        \n",
    "        # Assign to output mask\n",
    "        improved_mask[obj_mask > 0] = inst_id\n",
    "    \n",
    "    print(f\"âœ“ Applied morphological operations:\")\n",
    "    if MORPH_CLOSE_KERNEL > 0:\n",
    "        print(f\"  â€¢ Closing: kernel={MORPH_CLOSE_KERNEL}, iterations={MORPH_CLOSE_ITERATIONS}\")\n",
    "    if MORPH_DILATE_KERNEL > 0:\n",
    "        print(f\"  â€¢ Dilation: kernel={MORPH_DILATE_KERNEL}, iterations={MORPH_DILATE_ITERATIONS}\")\n",
    "    if MORPH_ERODE_KERNEL > 0:\n",
    "        print(f\"  â€¢ Erosion: kernel={MORPH_ERODE_KERNEL}, iterations={MORPH_ERODE_ITERATIONS}\")\n",
    "    \n",
    "    # Show before/after stats\n",
    "    before_pixels = np.sum(instance_mask > 0)\n",
    "    after_pixels = np.sum(improved_mask > 0)\n",
    "    change = after_pixels - before_pixels\n",
    "    change_pct = (change / before_pixels * 100) if before_pixels > 0 else 0\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Pixel changes:\")\n",
    "    print(f\"  Before: {before_pixels:,} pixels\")\n",
    "    print(f\"  After: {after_pixels:,} pixels\")\n",
    "    print(f\"  Change: {change:+,} pixels ({change_pct:+.1f}%)\")\n",
    "    \n",
    "    return improved_mask\n",
    "\n",
    "def calculate_shape_metrics(obj_mask):\n",
    "    \"\"\"\n",
    "    Calculate shape quality metrics for filtering\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Shape metrics (area, compactness, solidity, aspect_ratio, etc.)\n",
    "    \"\"\"\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(obj_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Basic metrics\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    if area == 0 or perimeter == 0:\n",
    "        return None\n",
    "    \n",
    "    # Bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    # Convex hull\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    hull_perimeter = cv2.arcLength(hull, True)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'area': area,\n",
    "        'perimeter': perimeter,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "    }\n",
    "    \n",
    "    # Compactness (circularity): 4Ï€*area/perimeterÂ²\n",
    "    # Perfect circle = 1.0, irregular = closer to 0\n",
    "    metrics['compactness'] = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0\n",
    "    \n",
    "    # Solidity: area / convex_hull_area\n",
    "    # Measures how \"solid\" the shape is (no concavities)\n",
    "    metrics['solidity'] = area / hull_area if hull_area > 0 else 0\n",
    "    \n",
    "    # Aspect ratio: width / height\n",
    "    metrics['aspect_ratio'] = max(w, h) / min(w, h) if min(w, h) > 0 else 0\n",
    "    \n",
    "    # Extent: area / bounding_box_area\n",
    "    # Measures how much of the bounding box is filled\n",
    "    bbox_area = w * h\n",
    "    metrics['extent'] = area / bbox_area if bbox_area > 0 else 0\n",
    "    \n",
    "    # Convexity: convex_hull_perimeter / perimeter\n",
    "    metrics['convexity'] = hull_perimeter / perimeter if perimeter > 0 else 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def filter_objects_by_quality(instance_mask):\n",
    "    \"\"\"\n",
    "    Filter objects based on size and shape quality\n",
    "    \"\"\"\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    cleaned_mask = np.zeros_like(instance_mask, dtype=np.uint16)\n",
    "    new_id = 1\n",
    "    \n",
    "    # Statistics\n",
    "    removed_reasons = {\n",
    "        'too_small': 0,\n",
    "        'too_large': 0,\n",
    "        'low_compactness': 0,\n",
    "        'low_solidity': 0,\n",
    "        'high_aspect_ratio': 0,\n",
    "        'low_convexity': 0,\n",
    "        'low_extent': 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FILTERING OBJECTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Criteria:\")\n",
    "    print(f\"  Area: {MIN_AREA:,} - {MAX_AREA:,} pixels\")\n",
    "    print(f\"  Compactness: â‰¥ {MIN_COMPACTNESS:.2f}\")\n",
    "    print(f\"  Solidity: â‰¥ {MIN_SOLIDITY:.2f}\")\n",
    "    print(f\"  Aspect ratio: â‰¤ {MAX_ASPECT_RATIO:.1f}\")\n",
    "    print(f\"  Convexity: â‰¥ {MIN_CONVEXITY:.2f}\")\n",
    "    print(f\"  Extent: â‰¥ {MIN_EXTENT:.2f}\")\n",
    "    \n",
    "    kept_objects = []\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        \n",
    "        # Calculate shape metrics\n",
    "        metrics = calculate_shape_metrics(obj_mask)\n",
    "        \n",
    "        if metrics is None:\n",
    "            removed_reasons['too_small'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Apply filters\n",
    "        keep = True\n",
    "        reason = None\n",
    "        \n",
    "        # Area filter\n",
    "        if metrics['area'] < MIN_AREA:\n",
    "            keep = False\n",
    "            reason = 'too_small'\n",
    "        elif metrics['area'] > MAX_AREA:\n",
    "            keep = False\n",
    "            reason = 'too_large'\n",
    "        # Compactness filter (remove irregular blobs)\n",
    "        elif metrics['compactness'] < MIN_COMPACTNESS:\n",
    "            keep = False\n",
    "            reason = 'low_compactness'\n",
    "        # Solidity filter (remove fragmented shapes)\n",
    "        elif metrics['solidity'] < MIN_SOLIDITY:\n",
    "            keep = False\n",
    "            reason = 'low_solidity'\n",
    "        # Aspect ratio filter (remove elongated shapes)\n",
    "        elif metrics['aspect_ratio'] > MAX_ASPECT_RATIO:\n",
    "            keep = False\n",
    "            reason = 'high_aspect_ratio'\n",
    "        # Convexity filter (remove very concave shapes)\n",
    "        elif metrics['convexity'] < MIN_CONVEXITY:\n",
    "            keep = False\n",
    "            reason = 'low_convexity'\n",
    "        # Extent filter (remove sparse/thin shapes)\n",
    "        elif metrics['extent'] < MIN_EXTENT:\n",
    "            keep = False\n",
    "            reason = 'low_extent'\n",
    "        \n",
    "        if keep:\n",
    "            cleaned_mask[obj_mask > 0] = new_id\n",
    "            kept_objects.append(metrics)\n",
    "            new_id += 1\n",
    "        else:\n",
    "            if reason:\n",
    "                removed_reasons[reason] += 1\n",
    "    \n",
    "    total_removed = sum(removed_reasons.values())\n",
    "    total_kept = new_id - 1\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Results:\")\n",
    "    print(f\"  âœ“ Kept: {total_kept} objects\")\n",
    "    print(f\"  âœ— Removed: {total_removed} objects\")\n",
    "    \n",
    "    if total_removed > 0:\n",
    "        print(f\"\\nðŸ“‹ Removal reasons:\")\n",
    "        for reason, count in removed_reasons.items():\n",
    "            if count > 0:\n",
    "                print(f\"  â€¢ {reason.replace('_', ' ').title()}: {count}\")\n",
    "    \n",
    "    if kept_objects:\n",
    "        areas = [m['area'] for m in kept_objects]\n",
    "        compactness = [m['compactness'] for m in kept_objects]\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Kept objects stats:\")\n",
    "        print(f\"  Area: {min(areas):,.0f} - {max(areas):,.0f} px (avg: {np.mean(areas):,.0f})\")\n",
    "        print(f\"  Compactness: {min(compactness):.3f} - {max(compactness):.3f} (avg: {np.mean(compactness):.3f})\")\n",
    "    \n",
    "    return cleaned_mask\n",
    "\n",
    "def extract_polygons_per_object(instance_mask, transform):\n",
    "    \"\"\"Extract ONE polygon per object\"\"\"\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    polygons = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXTRACTING POLYGONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        area = np.sum(obj_mask)\n",
    "        \n",
    "        # Extract polygon\n",
    "        for geom, val in shapes(obj_mask, mask=obj_mask, transform=transform):\n",
    "            if val > 0:\n",
    "                poly = shape(geom)\n",
    "                polygons.append({\n",
    "                    'polygon': poly,\n",
    "                    'id': int(inst_id),\n",
    "                    'area': int(area)\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    print(f\"âœ“ Extracted {len(polygons)} polygons\")\n",
    "    \n",
    "    if polygons:\n",
    "        areas = [p['area'] for p in polygons]\n",
    "        print(f\"\\nPolygon Statistics:\")\n",
    "        print(f\"  Count: {len(polygons)}\")\n",
    "        print(f\"  Area range: {min(areas):,} - {max(areas):,} pixels\")\n",
    "        print(f\"  Average: {np.mean(areas):,.0f} pixels\")\n",
    "    \n",
    "    return polygons\n",
    "\n",
    "def save_geojson(polygons, output_path, crs):\n",
    "    \"\"\"Save polygons to GeoJSON\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for poly_data in polygons:\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"id\": poly_data['id'],\n",
    "                \"area_pixels\": poly_data['area']\n",
    "            },\n",
    "            \"geometry\": mapping(poly_data['polygon'])\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"crs\": {\n",
    "            \"type\": \"name\",\n",
    "            \"properties\": {\"name\": str(crs) if crs else \"EPSG:4326\"}\n",
    "        },\n",
    "        \"features\": features\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(geojson, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ“ GeoJSON saved: {output_path}\")\n",
    "    print(f\"  â†’ {len(features)} polygons\")\n",
    "\n",
    "def extract_boundaries(instance_mask, thickness=4):\n",
    "    \"\"\"Extract boundary for each object\"\"\"\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    boundaries = np.zeros_like(instance_mask, dtype=np.uint8)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        edges = cv2.morphologyEx(obj_mask, cv2.MORPH_GRADIENT, kernel)\n",
    "        boundaries = np.maximum(boundaries, edges)\n",
    "    \n",
    "    if thickness > 1:\n",
    "        thick_kernel = np.ones((thickness, thickness), np.uint8)\n",
    "        boundaries = cv2.dilate(boundaries, thick_kernel, iterations=1)\n",
    "    \n",
    "    return boundaries\n",
    "\n",
    "def visualize_results(instance_mask, boundaries, polygons, save_path):\n",
    "    \"\"\"Create visualization\"\"\"\n",
    "    binary_mask = (instance_mask > 0).astype(np.uint8)\n",
    "    num_objects = len(np.unique(instance_mask)) - 1\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 18))\n",
    "    \n",
    "    # 1. Instance mask (color-coded)\n",
    "    axs[0, 0].imshow(instance_mask, cmap=\"nipy_spectral\", interpolation='nearest')\n",
    "    processing_text = []\n",
    "    if USE_WATERSHED_SEPARATION:\n",
    "        processing_text.append(\"Watershed\")\n",
    "    if USE_MORPHOLOGY:\n",
    "        processing_text.append(\"Morphology\")\n",
    "    title_suffix = f\" ({' + '.join(processing_text)})\" if processing_text else \"\"\n",
    "    axs[0, 0].set_title(f\"Instance Mask{title_suffix}\\n({num_objects} high-quality objects)\", \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axs[0, 0].axis(\"off\")\n",
    "    \n",
    "    # 2. With boundaries overlay\n",
    "    rgb = np.stack([binary_mask, binary_mask, binary_mask], axis=-1).astype(float)\n",
    "    rgb[boundaries > 0] = [1.0, 0, 0]\n",
    "    \n",
    "    axs[0, 1].imshow(rgb, interpolation='nearest')\n",
    "    axs[0, 1].set_title(f\"Objects with Boundaries\\n({len(polygons)} polygons, boundaries in RED)\", \n",
    "                        fontsize=14, fontweight='bold', color='darkgreen')\n",
    "    axs[0, 1].axis(\"off\")\n",
    "    \n",
    "    # 3. Binary mask\n",
    "    axs[1, 0].imshow(binary_mask, cmap=\"gray\", interpolation='nearest')\n",
    "    axs[1, 0].set_title(f\"Binary Mask\\n(All filtered objects)\", \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axs[1, 0].axis(\"off\")\n",
    "    \n",
    "    # 4. Boundaries only\n",
    "    boundary_display = np.zeros_like(instance_mask, dtype=np.uint8)\n",
    "    boundary_display[boundaries > 0] = 255\n",
    "    \n",
    "    axs[1, 1].imshow(boundary_display, cmap=\"gray\", interpolation='nearest')\n",
    "    axs[1, 1].set_title(f\"Boundaries Only\\n({BOUNDARY_THICKNESS}px thickness)\", \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axs[1, 1].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nâœ“ Visualization saved: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main pipeline\"\"\"\n",
    "    \n",
    "    if not Path(mask_path).exists():\n",
    "        raise FileNotFoundError(f\"Mask file not found: {mask_path}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SAM MASK â†’ FILTERED POLYGONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nInput: {mask_path}\")\n",
    "    \n",
    "    # Load SAM mask\n",
    "    instance_mask, profile, transform, crs = load_sam_mask(mask_path)\n",
    "    \n",
    "    # Apply watershed separation to separate touching objects\n",
    "    instance_mask = apply_watershed_separation(instance_mask)\n",
    "    \n",
    "    # Apply morphological operations to improve shapes\n",
    "    instance_mask = apply_morphological_operations(instance_mask)\n",
    "    \n",
    "    # Filter objects by size and shape quality\n",
    "    instance_mask = filter_objects_by_quality(instance_mask)\n",
    "    \n",
    "    # Extract polygons (one per object)\n",
    "    polygons = extract_polygons_per_object(instance_mask, transform)\n",
    "    \n",
    "    # Extract boundaries\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXTRACTING BOUNDARIES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Thickness: {BOUNDARY_THICKNESS}px\")\n",
    "    boundaries = extract_boundaries(instance_mask, BOUNDARY_THICKNESS)\n",
    "    print(f\"âœ“ Boundary pixels: {np.sum(boundaries > 0):,}\")\n",
    "    \n",
    "    # Save files\n",
    "    profile.update({\n",
    "        'count': 1,\n",
    "        'dtype': 'uint16',\n",
    "        'compress': 'lzw',\n",
    "        'nodata': 0\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SAVING FILES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    with rasterio.open(clean_mask_path, \"w\", **profile) as dst:\n",
    "        dst.write(instance_mask.astype(np.uint16), 1)\n",
    "    print(f\"âœ“ Instance mask: {clean_mask_path}\")\n",
    "    \n",
    "    if CREATE_BOUNDARY_FILE:\n",
    "        profile_boundary = profile.copy()\n",
    "        profile_boundary['dtype'] = 'uint8'\n",
    "        \n",
    "        with rasterio.open(boundaries_path, \"w\", **profile_boundary) as dst:\n",
    "            dst.write(boundaries, 1)\n",
    "        print(f\"âœ“ Boundaries: {boundaries_path}\")\n",
    "    \n",
    "    if SAVE_GEOJSON:\n",
    "        save_geojson(polygons, polygons_geojson, crs)\n",
    "    \n",
    "    # Visualize\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GENERATING VISUALIZATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    visualize_results(instance_mask, boundaries, polygons, \"polygons_visualization.png\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âœ“ COMPLETE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nOutput files:\")\n",
    "    print(f\"  1. {clean_mask_path} - Filtered instance mask\")\n",
    "    print(f\"  2. {boundaries_path} - Boundaries\")\n",
    "    print(f\"  3. {polygons_geojson} - Polygons (GeoJSON) â† USE THIS!\")\n",
    "    print(f\"  4. polygons_visualization.png - Visualization\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Processing applied:\")\n",
    "    if USE_WATERSHED_SEPARATION:\n",
    "        print(f\"  â€¢ Watershed separation: separated touching objects\")\n",
    "    if USE_MORPHOLOGY:\n",
    "        print(f\"  â€¢ Morphological processing: filled holes and smoothed edges\")\n",
    "    print(f\"  â€¢ Quality filtering: removed small/irregular shapes\")\n",
    "    print(f\"\\nâœ“ Only high-quality objects with proper shapes!\")\n",
    "    \n",
    "    return instance_mask, boundaries, polygons\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        instance_mask, boundaries, polygons = main()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10905395-5a4f-4e3f-bef2-a5b5353a130d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# --- Configuration ---\n",
    "polygons_geojson = \"polygons.geojson1\"\n",
    "original_image_path = \"tiff_testing/tile_20480_40960.tif\"\n",
    "\n",
    "GRID_COLS = 4  # Number of columns in the grid\n",
    "POLYGON_COLOR = 'red'  # Boundary color\n",
    "LINE_WIDTH = 2  # Boundary thickness\n",
    "SHOW_POLYGON_ID = True  # Show polygon ID in title\n",
    "\n",
    "def load_polygons(geojson_path):\n",
    "    \"\"\"Load polygons from GeoJSON file\"\"\"\n",
    "    print(f\"Loading polygons from: {geojson_path}\")\n",
    "    gdf = gpd.read_file(geojson_path)\n",
    "    print(f\"âœ“ Loaded {len(gdf)} polygons\")\n",
    "    \n",
    "    # Show some info\n",
    "    if 'area_pixels' in gdf.columns:\n",
    "        print(f\"\\nPolygon Statistics:\")\n",
    "        print(f\"  Area range: {gdf['area_pixels'].min():,} - {gdf['area_pixels'].max():,} pixels\")\n",
    "        print(f\"  Average area: {gdf['area_pixels'].mean():,.0f} pixels\")\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def load_original_image(image_path):\n",
    "    \"\"\"Load original raster image\"\"\"\n",
    "    print(f\"\\nLoading original image: {image_path}\")\n",
    "    \n",
    "    with rasterio.open(image_path) as src:\n",
    "        img_data = src.read()\n",
    "        img_transform = src.transform\n",
    "        img_crs = src.crs\n",
    "        \n",
    "        # Calculate extent for plotting\n",
    "        img_extent = [\n",
    "            img_transform[2],  # left\n",
    "            img_transform[2] + img_transform[0] * src.width,  # right\n",
    "            img_transform[5] + img_transform[4] * src.height,  # bottom\n",
    "            img_transform[5]  # top\n",
    "        ]\n",
    "    \n",
    "    print(f\"âœ“ Image shape: {img_data.shape}\")\n",
    "    print(f\"âœ“ Image CRS: {img_crs}\")\n",
    "    \n",
    "    # Prepare RGB or grayscale display\n",
    "    if img_data.shape[0] >= 3:\n",
    "        # RGB image\n",
    "        rgb = np.transpose(img_data[:3], (1, 2, 0))\n",
    "        \n",
    "        # Normalize to 0-255 if needed\n",
    "        if rgb.max() > 255:\n",
    "            rgb = (rgb / rgb.max() * 255).astype(np.uint8)\n",
    "        \n",
    "        display_img = rgb\n",
    "        cmap = None\n",
    "    else:\n",
    "        # Grayscale\n",
    "        display_img = img_data[0]\n",
    "        cmap = 'gray'\n",
    "    \n",
    "    return display_img, img_extent, cmap\n",
    "\n",
    "def visualize_polygons_grid(gdf, display_img, img_extent, cmap=None, \n",
    "                           n_cols=4, figsize_per_plot=(4, 4)):\n",
    "    \"\"\"\n",
    "    Visualize each polygon separately in a grid\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Polygons to visualize\n",
    "    display_img : numpy.ndarray\n",
    "        Image to display as background\n",
    "    img_extent : list\n",
    "        [left, right, bottom, top] extent for image\n",
    "    cmap : str, optional\n",
    "        Colormap for grayscale images\n",
    "    n_cols : int\n",
    "        Number of columns in grid\n",
    "    figsize_per_plot : tuple\n",
    "        Size of each subplot\n",
    "    \"\"\"\n",
    "    n_polygons = len(gdf)\n",
    "    n_rows = int(np.ceil(n_polygons / n_cols))\n",
    "    \n",
    "    fig_width = figsize_per_plot[0] * n_cols\n",
    "    fig_height = figsize_per_plot[1] * n_rows\n",
    "    \n",
    "    print(f\"\\nCreating visualization grid:\")\n",
    "    print(f\"  Grid: {n_rows} rows Ã— {n_cols} cols\")\n",
    "    print(f\"  Figure size: {fig_width} Ã— {fig_height}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height))\n",
    "    axes = axes.flatten() if n_polygons > 1 else [axes]\n",
    "    \n",
    "    # Plot each polygon\n",
    "    for idx, (_, row) in enumerate(gdf.iterrows()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Display original image\n",
    "        if cmap:\n",
    "            ax.imshow(display_img, cmap=cmap, extent=img_extent)\n",
    "        else:\n",
    "            ax.imshow(display_img, extent=img_extent)\n",
    "        \n",
    "        # Plot this polygon\n",
    "        gdf_single = gpd.GeoDataFrame(geometry=[row.geometry], crs=gdf.crs)\n",
    "        gdf_single.boundary.plot(ax=ax, edgecolor=POLYGON_COLOR, linewidth=LINE_WIDTH)\n",
    "        \n",
    "        # Set title\n",
    "        if SHOW_POLYGON_ID and 'id' in gdf.columns:\n",
    "            title = f\"Polygon {idx+1} (ID: {row['id']})\"\n",
    "        else:\n",
    "            title = f\"Polygon {idx+1}\"\n",
    "        \n",
    "        # Add area to title if available\n",
    "        if 'area_pixels' in gdf.columns:\n",
    "            title += f\"\\n{row['area_pixels']:,} px\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=10, fontweight='bold')\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_polygons, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = \"polygons_grid_visualization.png\"\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nâœ“ Saved visualization: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def visualize_polygons_overlay(gdf, display_img, img_extent, cmap=None):\n",
    "    \"\"\"\n",
    "    Visualize all polygons overlaid on the original image\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Display original image\n",
    "    if cmap:\n",
    "        ax.imshow(display_img, cmap=cmap, extent=img_extent)\n",
    "    else:\n",
    "        ax.imshow(display_img, extent=img_extent)\n",
    "    \n",
    "    # Plot all polygons\n",
    "    gdf.boundary.plot(ax=ax, edgecolor=POLYGON_COLOR, linewidth=LINE_WIDTH)\n",
    "    \n",
    "    ax.set_title(f\"All {len(gdf)} Polygons Overlay\", fontsize=16, fontweight='bold')\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = \"polygons_overlay_visualization.png\"\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nâœ“ Saved overlay visualization: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main visualization pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"VISUALIZE POLYGONS FROM GEOJSON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load polygons\n",
    "    gdf = load_polygons(polygons_geojson)\n",
    "    \n",
    "    # Load original image\n",
    "    display_img, img_extent, cmap = load_original_image(original_image_path)\n",
    "    \n",
    "    # Visualize each polygon separately in grid\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Creating grid visualization (one polygon per subplot)...\")\n",
    "    print(\"=\" * 60)\n",
    "    visualize_polygons_grid(gdf, display_img, img_extent, cmap, n_cols=GRID_COLS)\n",
    "    \n",
    "    # Visualize all polygons overlaid\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Creating overlay visualization (all polygons)...\")\n",
    "    print(\"=\" * 60)\n",
    "    visualize_polygons_overlay(gdf, display_img, img_extent, cmap)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"VISUALIZATION COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nOutput files:\")\n",
    "    print(\"  1. polygons_grid_visualization.png - Each polygon separate\")\n",
    "    print(\"  2. polygons_overlay_visualization.png - All polygons overlaid\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f848aa-49b6-4e2f-a4d6-37b225a54b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Geosam)",
   "language": "python",
   "name": "geosam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
