{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed8d2fe-f638-4e34-998e-c068bf0de747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewImages.ipynb  new_test_images.zip  test2_threshold.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fe71c3-e25e-42c1-b54b-209cf204659b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip \"new_test_images.zip\"\n",
    "# !unzip \"test2_threshold.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806b9add-1780-440b-a535-8acf61c07156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from samgeo import SamGeo2\n",
    "\n",
    "sam2 = SamGeo2(\n",
    "    model_id=\"sam2-hiera-large\",\n",
    "    apply_postprocessing=True,\n",
    "    points_per_side=64,        \n",
    "    points_per_batch=128,\n",
    "    pred_iou_thresh=0.7,         \n",
    "    stability_score_thresh=0.85,\n",
    "    stability_score_offset=0.7,\n",
    "    crop_n_layers=1,          \n",
    "    box_nms_thresh=0.8,\n",
    "    min_mask_region_area=10.0,   \n",
    "    use_m2m=True,              \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6e054-959e-4650-90c5-345fa2a0095b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = \"new_test_images/tile_HK_00110.png\"\n",
    "\n",
    "sam2.generate(image_path, georeference=False)\n",
    "\n",
    "sam2.save_masks(\n",
    "    output=\"outputs2/tile_HK_00110_masks.tif\",\n",
    "    georeference=False\n",
    ")\n",
    "\n",
    "sam2.show_anns(\n",
    "    axis=\"off\",\n",
    "    alpha=0.7,\n",
    "    output=\"annotations.tif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d80825-24f3-4f43-b1ca-aa59dede980b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import cv2\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, mapping\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGE_PATH = \"new_test_images/tile_HK_00110.png\"\n",
    "mask_path = \"outputs2/tile_HK_00110_masks.tif\"\n",
    "clean_mask_path = \"masks_clean.tif\"\n",
    "boundaries_path = \"masks_boundaries.tif\"\n",
    "polygons_geojson = \"polygons.geojson\"\n",
    "\n",
    "# --- Watershed Separation (for touching objects) ---\n",
    "USE_WATERSHED_SEPARATION = True  # Separate touching objects using watershed\n",
    "WATERSHED_THRESHOLD = 0.2       \n",
    "\n",
    "# --- Morphological Processing ---\n",
    "USE_MORPHOLOGY = False        # Apply morphological operations to improve shapes\n",
    "MORPH_CLOSE_KERNEL = 3       # Kernel size for closing (fill small holes)\n",
    "MORPH_CLOSE_ITERATIONS = 1   # How many times to apply closing\n",
    "MORPH_DILATE_KERNEL = 0      # Kernel size for dilation (expand objects)\n",
    "MORPH_DILATE_ITERATIONS = 0  # How many times to dilate\n",
    "MORPH_ERODE_KERNEL = 0       # Kernel size for erosion (shrink back slightly)\n",
    "MORPH_ERODE_ITERATIONS = 0   # How many times to erode (use to smooth after dilation)\n",
    "\n",
    "# --- Filtering Parameters ---\n",
    "MIN_AREA = 5000              # Minimum area in pixels (increase to remove smaller blobs)\n",
    "MAX_AREA = 20000000          # Maximum area (remove if too large)\n",
    "\n",
    "# Shape quality filters\n",
    "MIN_COMPACTNESS = 0.01       # Remove irregular shapes (0-1, higher = more compact)\n",
    "MIN_SOLIDITY = 0.05          # Remove fragmented shapes (0-1, area/convex_hull)\n",
    "MAX_ASPECT_RATIO = 100.0      # Remove elongated shapes (width/height ratio)\n",
    "MIN_CONVEXITY = 0.5         # Remove concave/irregular shapes (0-1)\n",
    "MIN_EXTENT = 0.10            # Remove thin/sparse shapes (area/bounding_box)\n",
    "\n",
    "BOUNDARY_THICKNESS = 5      \n",
    "CREATE_BOUNDARY_FILE = True\n",
    "SAVE_GEOJSON = True\n",
    "\n",
    "def load_sam_mask(mask_path):\n",
    "    \"\"\"Load SAM mask and convert to instance mask\"\"\"\n",
    "    with rasterio.open(mask_path) as src:\n",
    "        mask_data = src.read()\n",
    "        profile = src.profile.copy()\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MASK ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Shape: {mask_data.shape}\")\n",
    "    print(f\"Dtype: {mask_data.dtype}\")\n",
    "    print(f\"Bands: {mask_data.shape[0] if mask_data.ndim == 3 else 1}\")\n",
    "    \n",
    "    # Handle multi-band masks\n",
    "    if mask_data.ndim == 3 and mask_data.shape[0] > 1:\n",
    "        print(f\"\\n‚úì Multi-band mask: {mask_data.shape[0]} bands\")\n",
    "        \n",
    "        instance_mask = np.zeros(mask_data.shape[1:], dtype=np.uint16)\n",
    "        \n",
    "        print(f\"\\nAnalyzing bands:\")\n",
    "        valid_bands = 0\n",
    "        for band_idx in range(mask_data.shape[0]):\n",
    "            band = mask_data[band_idx]\n",
    "            nonzero = np.count_nonzero(band > 0)\n",
    "            \n",
    "            if nonzero > 0:\n",
    "                valid_bands += 1\n",
    "                band_mask = band > 0\n",
    "                instance_mask[band_mask & (instance_mask == 0)] = band_idx + 1\n",
    "                \n",
    "                if band_idx < 10:\n",
    "                    print(f\"  Band {band_idx+1}: {nonzero:,} pixels\")\n",
    "        \n",
    "        if mask_data.shape[0] > 10:\n",
    "            print(f\"  ... and {mask_data.shape[0] - 10} more bands\")\n",
    "        \n",
    "        print(f\"\\n‚úì Converted {valid_bands} bands\")\n",
    "        \n",
    "    else:\n",
    "        instance_mask = mask_data.squeeze()\n",
    "        unique_vals = np.unique(instance_mask)\n",
    "        unique_vals = unique_vals[unique_vals > 0]\n",
    "        \n",
    "        if len(unique_vals) > 1:\n",
    "            print(f\"\\n‚úì Single-band instance mask: {len(unique_vals)} objects\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö† Binary mask - separating connected regions\")\n",
    "            instance_mask, num = ndimage.label(instance_mask > 0)\n",
    "            print(f\"‚Üí Found {num} connected regions\")\n",
    "    \n",
    "    num_instances = len(np.unique(instance_mask)) - 1\n",
    "    total_pixels = np.sum(instance_mask > 0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULT: {num_instances} objects, {total_pixels:,} pixels\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return instance_mask, profile, transform, crs\n",
    "\n",
    "def apply_watershed_separation(instance_mask):\n",
    "    \"\"\"\n",
    "    Apply watershed algorithm to separate touching objects\n",
    "    This is useful when SAM detects objects that are touching/overlapping\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    instance_mask : numpy.ndarray\n",
    "        Instance mask where objects might be touching\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray : Instance mask with separated objects\n",
    "    \"\"\"\n",
    "    if not USE_WATERSHED_SEPARATION:\n",
    "        return instance_mask\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"WATERSHED SEPARATION (Separate Touching Objects)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create binary mask of all objects\n",
    "    binary_mask = (instance_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    # Distance transform to find object centers\n",
    "    dist = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 3)\n",
    "    \n",
    "    # Normalize distance\n",
    "    dist_norm = cv2.normalize(dist, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # Find local maxima (object centers) with configurable threshold\n",
    "    _, peaks = cv2.threshold(dist_norm, WATERSHED_THRESHOLD * dist_norm.max(), 255, cv2.THRESH_BINARY)\n",
    "    peaks = peaks.astype(np.uint8)\n",
    "    \n",
    "    # Label the peaks (these become watershed markers)\n",
    "    _, markers = cv2.connectedComponents(peaks)\n",
    "    \n",
    "    # Small dilation of markers to ensure they're inside objects\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    markers = cv2.dilate(markers.astype(np.uint8), kernel, iterations=1)\n",
    "    markers = markers.astype(np.int32)\n",
    "    \n",
    "    # Mark background\n",
    "    markers[binary_mask == 0] = 0\n",
    "    \n",
    "    # Apply watershed\n",
    "    binary_3ch = cv2.cvtColor(binary_mask * 255, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(binary_3ch, markers)\n",
    "    \n",
    "    # Create separated instance mask\n",
    "    # Watershed boundaries are marked as -1, we set them to 0\n",
    "    separated_mask = np.where(markers > 0, markers, 0).astype(np.uint16)\n",
    "    \n",
    "    # Count objects before and after\n",
    "    before_count = len(np.unique(instance_mask)) - 1\n",
    "    after_count = len(np.unique(separated_mask)) - 1\n",
    "    \n",
    "    print(f\"‚úì Watershed separation applied:\")\n",
    "    print(f\"  Threshold: {WATERSHED_THRESHOLD}\")\n",
    "    print(f\"  Objects before: {before_count}\")\n",
    "    print(f\"  Objects after: {after_count}\")\n",
    "    print(f\"  New objects separated: {after_count - before_count}\")\n",
    "    \n",
    "    return separated_mask\n",
    "\n",
    "def apply_morphological_operations(instance_mask):\n",
    "    \"\"\"\n",
    "    Apply morphological operations to improve object shapes\n",
    "    - Closing: fills small holes and gaps\n",
    "    - Dilation: expands objects, smooths edges\n",
    "    - Erosion: shrinks objects back (optional, for smoothing)\n",
    "    \"\"\"\n",
    "    if not USE_MORPHOLOGY:\n",
    "        return instance_mask\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MORPHOLOGICAL PROCESSING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    improved_mask = np.zeros_like(instance_mask, dtype=np.uint16)\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        \n",
    "        # 1. Morphological Closing (fill small holes and gaps)\n",
    "        if MORPH_CLOSE_KERNEL > 0 and MORPH_CLOSE_ITERATIONS > 0:\n",
    "            close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                                     (MORPH_CLOSE_KERNEL, MORPH_CLOSE_KERNEL))\n",
    "            obj_mask = cv2.morphologyEx(obj_mask, cv2.MORPH_CLOSE, close_kernel, \n",
    "                                       iterations=MORPH_CLOSE_ITERATIONS)\n",
    "        \n",
    "        # 2. Dilation (expand object, smooth edges)\n",
    "        if MORPH_DILATE_KERNEL > 0 and MORPH_DILATE_ITERATIONS > 0:\n",
    "            dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                                      (MORPH_DILATE_KERNEL, MORPH_DILATE_KERNEL))\n",
    "            obj_mask = cv2.dilate(obj_mask, dilate_kernel, iterations=MORPH_DILATE_ITERATIONS)\n",
    "        \n",
    "        # 3. Erosion (shrink back slightly to smooth, optional)\n",
    "        if MORPH_ERODE_KERNEL > 0 and MORPH_ERODE_ITERATIONS > 0:\n",
    "            erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                                     (MORPH_ERODE_KERNEL, MORPH_ERODE_KERNEL))\n",
    "            obj_mask = cv2.erode(obj_mask, erode_kernel, iterations=MORPH_ERODE_ITERATIONS)\n",
    "        \n",
    "        # Assign to output mask\n",
    "        improved_mask[obj_mask > 0] = inst_id\n",
    "    \n",
    "    print(f\"‚úì Applied morphological operations:\")\n",
    "    if MORPH_CLOSE_KERNEL > 0:\n",
    "        print(f\"  ‚Ä¢ Closing: kernel={MORPH_CLOSE_KERNEL}, iterations={MORPH_CLOSE_ITERATIONS}\")\n",
    "    if MORPH_DILATE_KERNEL > 0:\n",
    "        print(f\"  ‚Ä¢ Dilation: kernel={MORPH_DILATE_KERNEL}, iterations={MORPH_DILATE_ITERATIONS}\")\n",
    "    if MORPH_ERODE_KERNEL > 0:\n",
    "        print(f\"  ‚Ä¢ Erosion: kernel={MORPH_ERODE_KERNEL}, iterations={MORPH_ERODE_ITERATIONS}\")\n",
    "    \n",
    "    # Show before/after stats\n",
    "    before_pixels = np.sum(instance_mask > 0)\n",
    "    after_pixels = np.sum(improved_mask > 0)\n",
    "    change = after_pixels - before_pixels\n",
    "    change_pct = (change / before_pixels * 100) if before_pixels > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä Pixel changes:\")\n",
    "    print(f\"  Before: {before_pixels:,} pixels\")\n",
    "    print(f\"  After: {after_pixels:,} pixels\")\n",
    "    print(f\"  Change: {change:+,} pixels ({change_pct:+.1f}%)\")\n",
    "    \n",
    "    return improved_mask\n",
    "\n",
    "def calculate_shape_metrics(obj_mask):\n",
    "    \"\"\"\n",
    "    Calculate shape quality metrics for filtering\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Shape metrics (area, compactness, solidity, aspect_ratio, etc.)\n",
    "    \"\"\"\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(obj_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Basic metrics\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    if area == 0 or perimeter == 0:\n",
    "        return None\n",
    "    \n",
    "    # Bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    # Convex hull\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    hull_perimeter = cv2.arcLength(hull, True)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'area': area,\n",
    "        'perimeter': perimeter,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "    }\n",
    "    \n",
    "    # Compactness (circularity): 4œÄ*area/perimeter¬≤\n",
    "    # Perfect circle = 1.0, irregular = closer to 0\n",
    "    metrics['compactness'] = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0\n",
    "    \n",
    "    # Solidity: area / convex_hull_area\n",
    "    # Measures how \"solid\" the shape is (no concavities)\n",
    "    metrics['solidity'] = area / hull_area if hull_area > 0 else 0\n",
    "    \n",
    "    # Aspect ratio: width / height\n",
    "    metrics['aspect_ratio'] = max(w, h) / min(w, h) if min(w, h) > 0 else 0\n",
    "    \n",
    "    # Extent: area / bounding_box_area\n",
    "    # Measures how much of the bounding box is filled\n",
    "    bbox_area = w * h\n",
    "    metrics['extent'] = area / bbox_area if bbox_area > 0 else 0\n",
    "    \n",
    "    # Convexity: convex_hull_perimeter / perimeter\n",
    "    metrics['convexity'] = hull_perimeter / perimeter if perimeter > 0 else 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def filter_objects_by_quality(instance_mask):\n",
    "    \"\"\"\n",
    "    Filter objects based on size and shape quality\n",
    "    \"\"\"\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    cleaned_mask = np.zeros_like(instance_mask, dtype=np.uint16)\n",
    "    new_id = 1\n",
    "    \n",
    "    # Statistics\n",
    "    removed_reasons = {\n",
    "        'too_small': 0,\n",
    "        'too_large': 0,\n",
    "        'low_compactness': 0,\n",
    "        'low_solidity': 0,\n",
    "        'high_aspect_ratio': 0,\n",
    "        'low_convexity': 0,\n",
    "        'low_extent': 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FILTERING OBJECTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Criteria:\")\n",
    "    print(f\"  Area: {MIN_AREA:,} - {MAX_AREA:,} pixels\")\n",
    "    print(f\"  Compactness: ‚â• {MIN_COMPACTNESS:.2f}\")\n",
    "    print(f\"  Solidity: ‚â• {MIN_SOLIDITY:.2f}\")\n",
    "    print(f\"  Aspect ratio: ‚â§ {MAX_ASPECT_RATIO:.1f}\")\n",
    "    print(f\"  Convexity: ‚â• {MIN_CONVEXITY:.2f}\")\n",
    "    print(f\"  Extent: ‚â• {MIN_EXTENT:.2f}\")\n",
    "    \n",
    "    kept_objects = []\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        \n",
    "        # Calculate shape metrics\n",
    "        metrics = calculate_shape_metrics(obj_mask)\n",
    "        \n",
    "        if metrics is None:\n",
    "            removed_reasons['too_small'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Apply filters\n",
    "        keep = True\n",
    "        reason = None\n",
    "        \n",
    "        # Area filter\n",
    "        if metrics['area'] < MIN_AREA:\n",
    "            keep = False\n",
    "            reason = 'too_small'\n",
    "        elif metrics['area'] > MAX_AREA:\n",
    "            keep = False\n",
    "            reason = 'too_large'\n",
    "        # Compactness filter (remove irregular blobs)\n",
    "        elif metrics['compactness'] < MIN_COMPACTNESS:\n",
    "            keep = False\n",
    "            reason = 'low_compactness'\n",
    "        # Solidity filter (remove fragmented shapes)\n",
    "        elif metrics['solidity'] < MIN_SOLIDITY:\n",
    "            keep = False\n",
    "            reason = 'low_solidity'\n",
    "        # Aspect ratio filter (remove elongated shapes)\n",
    "        elif metrics['aspect_ratio'] > MAX_ASPECT_RATIO:\n",
    "            keep = False\n",
    "            reason = 'high_aspect_ratio'\n",
    "        # Convexity filter (remove very concave shapes)\n",
    "        elif metrics['convexity'] < MIN_CONVEXITY:\n",
    "            keep = False\n",
    "            reason = 'low_convexity'\n",
    "        # Extent filter (remove sparse/thin shapes)\n",
    "        elif metrics['extent'] < MIN_EXTENT:\n",
    "            keep = False\n",
    "            reason = 'low_extent'\n",
    "        \n",
    "        if keep:\n",
    "            cleaned_mask[obj_mask > 0] = new_id\n",
    "            kept_objects.append(metrics)\n",
    "            new_id += 1\n",
    "        else:\n",
    "            if reason:\n",
    "                removed_reasons[reason] += 1\n",
    "    \n",
    "    total_removed = sum(removed_reasons.values())\n",
    "    total_kept = new_id - 1\n",
    "    \n",
    "    print(f\"\\nüìä Results:\")\n",
    "    print(f\"  ‚úì Kept: {total_kept} objects\")\n",
    "    print(f\"  ‚úó Removed: {total_removed} objects\")\n",
    "    \n",
    "    if total_removed > 0:\n",
    "        print(f\"\\nüìã Removal reasons:\")\n",
    "        for reason, count in removed_reasons.items():\n",
    "            if count > 0:\n",
    "                print(f\"  ‚Ä¢ {reason.replace('_', ' ').title()}: {count}\")\n",
    "    \n",
    "    if kept_objects:\n",
    "        areas = [m['area'] for m in kept_objects]\n",
    "        compactness = [m['compactness'] for m in kept_objects]\n",
    "        \n",
    "        print(f\"\\nüìà Kept objects stats:\")\n",
    "        print(f\"  Area: {min(areas):,.0f} - {max(areas):,.0f} px (avg: {np.mean(areas):,.0f})\")\n",
    "        print(f\"  Compactness: {min(compactness):.3f} - {max(compactness):.3f} (avg: {np.mean(compactness):.3f})\")\n",
    "    \n",
    "    return cleaned_mask\n",
    "\n",
    "def extract_polygons_per_object(instance_mask, transform):\n",
    "    \"\"\"Extract ONE polygon per object\"\"\"\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    polygons = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXTRACTING POLYGONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        area = np.sum(obj_mask)\n",
    "        \n",
    "        # Extract polygon\n",
    "        for geom, val in shapes(obj_mask, mask=obj_mask, transform=transform):\n",
    "            if val > 0:\n",
    "                poly = shape(geom)\n",
    "                polygons.append({\n",
    "                    'polygon': poly,\n",
    "                    'id': int(inst_id),\n",
    "                    'area': int(area)\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    print(f\"‚úì Extracted {len(polygons)} polygons\")\n",
    "    \n",
    "    if polygons:\n",
    "        areas = [p['area'] for p in polygons]\n",
    "        print(f\"\\nPolygon Statistics:\")\n",
    "        print(f\"  Count: {len(polygons)}\")\n",
    "        print(f\"  Area range: {min(areas):,} - {max(areas):,} pixels\")\n",
    "        print(f\"  Average: {np.mean(areas):,.0f} pixels\")\n",
    "    \n",
    "    return polygons\n",
    "\n",
    "def save_geojson(polygons, output_path, crs):\n",
    "    \"\"\"Save polygons to GeoJSON\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for poly_data in polygons:\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"id\": poly_data['id'],\n",
    "                \"area_pixels\": poly_data['area']\n",
    "            },\n",
    "            \"geometry\": mapping(poly_data['polygon'])\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"crs\": {\n",
    "            \"type\": \"name\",\n",
    "            \"properties\": {\"name\": str(crs) if crs else \"EPSG:4326\"}\n",
    "        },\n",
    "        \"features\": features\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(geojson, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úì GeoJSON saved: {output_path}\")\n",
    "    print(f\"  ‚Üí {len(features)} polygons\")\n",
    "\n",
    "def extract_boundaries(instance_mask, thickness=4):\n",
    "    \"\"\"Extract boundary for each object\"\"\"\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    boundaries = np.zeros_like(instance_mask, dtype=np.uint8)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        edges = cv2.morphologyEx(obj_mask, cv2.MORPH_GRADIENT, kernel)\n",
    "        boundaries = np.maximum(boundaries, edges)\n",
    "    \n",
    "    if thickness > 1:\n",
    "        thick_kernel = np.ones((thickness, thickness), np.uint8)\n",
    "        boundaries = cv2.dilate(boundaries, thick_kernel, iterations=1)\n",
    "    \n",
    "    return boundaries\n",
    "\n",
    "def load_real_image(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        img = src.read()\n",
    "        \n",
    "    # Convert to HWC for plotting\n",
    "    if img.shape[0] == 3:\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "    else:\n",
    "        img = img.squeeze()\n",
    "\n",
    "    # Normalize for display\n",
    "    img = img.astype(np.float32)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "\n",
    "    return img\n",
    "def overlay_boundaries_on_image(image, boundaries):\n",
    "    if image.ndim == 2:\n",
    "        image = np.stack([image]*3, axis=-1)\n",
    "\n",
    "    overlay = image.copy()\n",
    "    overlay[boundaries > 0] = [1.0, 0.0, 0.0]  # red boundaries\n",
    "    return overlay\n",
    "def overlay_polygons_on_image(image, polygons):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for poly_data in polygons:\n",
    "        x, y = poly_data['polygon'].exterior.xy\n",
    "        ax.plot(x, y, color='lime', linewidth=1)\n",
    "\n",
    "    ax.set_title(\"Real Image + Polygons\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_results(instance_mask, boundaries, polygons, save_path, real_image=None):\n",
    "    binary_mask = (instance_mask > 0).astype(np.uint8)\n",
    "    num_objects = len(np.unique(instance_mask)) - 1\n",
    "\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(20, 26))\n",
    "\n",
    "    # ---- Real image ----\n",
    "    if real_image is not None:\n",
    "        axs[0, 0].imshow(real_image)\n",
    "        axs[0, 0].set_title(\"Original Image\", fontsize=14, fontweight='bold')\n",
    "        axs[0, 0].axis(\"off\")\n",
    "\n",
    "        overlay = overlay_boundaries_on_image(real_image, boundaries)\n",
    "        axs[0, 1].imshow(overlay)\n",
    "        axs[0, 1].set_title(\"Image + Boundaries\", fontsize=14, fontweight='bold')\n",
    "        axs[0, 1].axis(\"off\")\n",
    "    else:\n",
    "        axs[0, 0].axis(\"off\")\n",
    "        axs[0, 1].axis(\"off\")\n",
    "\n",
    "    # ---- Instance mask ----\n",
    "    axs[1, 0].imshow(instance_mask, cmap=\"nipy_spectral\", interpolation='nearest')\n",
    "    axs[1, 0].set_title(f\"Instance Mask ({num_objects} objects)\", fontsize=14, fontweight='bold')\n",
    "    axs[1, 0].axis(\"off\")\n",
    "\n",
    "    # ---- Binary + boundaries ----\n",
    "    rgb = np.stack([binary_mask]*3, axis=-1).astype(float)\n",
    "    rgb[boundaries > 0] = [1, 0, 0]\n",
    "\n",
    "    axs[1, 1].imshow(rgb)\n",
    "    axs[1, 1].set_title(\"Binary Mask + Boundaries\", fontsize=14, fontweight='bold')\n",
    "    axs[1, 1].axis(\"off\")\n",
    "\n",
    "    # ---- Boundaries only ----\n",
    "    axs[2, 0].imshow(boundaries, cmap=\"gray\")\n",
    "    axs[2, 0].set_title(\"Boundaries Only\", fontsize=14, fontweight='bold')\n",
    "    axs[2, 0].axis(\"off\")\n",
    "\n",
    "    # ---- Polygons on image ----\n",
    "    if real_image is not None:\n",
    "        axs[2, 1].imshow(real_image)\n",
    "        for poly in polygons:\n",
    "            x, y = poly['polygon'].exterior.xy\n",
    "            axs[2, 1].plot(x, y, color='lime', linewidth=1)\n",
    "        axs[2, 1].set_title(\"Image + Polygons\", fontsize=14, fontweight='bold')\n",
    "        axs[2, 1].axis(\"off\")\n",
    "    else:\n",
    "        axs[2, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main pipeline\"\"\"\n",
    "    \n",
    "    if not Path(mask_path).exists():\n",
    "        raise FileNotFoundError(f\"Mask file not found: {mask_path}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SAM MASK ‚Üí FILTERED POLYGONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nInput: {mask_path}\")\n",
    "    \n",
    "    # Load SAM mask\n",
    "    instance_mask, profile, transform, crs = load_sam_mask(mask_path)\n",
    "    \n",
    "    # Apply watershed separation to separate touching objects\n",
    "    instance_mask = apply_watershed_separation(instance_mask)\n",
    "    \n",
    "    # Apply morphological operations to improve shapes\n",
    "    instance_mask = apply_morphological_operations(instance_mask)\n",
    "    \n",
    "    # Filter objects by size and shape quality\n",
    "    instance_mask = filter_objects_by_quality(instance_mask)\n",
    "    \n",
    "    # Extract polygons (one per object)\n",
    "    polygons = extract_polygons_per_object(instance_mask, transform)\n",
    "    \n",
    "    # Extract boundaries\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXTRACTING BOUNDARIES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Thickness: {BOUNDARY_THICKNESS}px\")\n",
    "    boundaries = extract_boundaries(instance_mask, BOUNDARY_THICKNESS)\n",
    "    print(f\"‚úì Boundary pixels: {np.sum(boundaries > 0):,}\")\n",
    "    \n",
    "    # Save files\n",
    "    profile.update({\n",
    "        'count': 1,\n",
    "        'dtype': 'uint16',\n",
    "        'compress': 'lzw',\n",
    "        'nodata': 0\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SAVING FILES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    with rasterio.open(clean_mask_path, \"w\", **profile) as dst:\n",
    "        dst.write(instance_mask.astype(np.uint16), 1)\n",
    "    print(f\"‚úì Instance mask: {clean_mask_path}\")\n",
    "    \n",
    "    if CREATE_BOUNDARY_FILE:\n",
    "        profile_boundary = profile.copy()\n",
    "        profile_boundary['dtype'] = 'uint8'\n",
    "        \n",
    "        with rasterio.open(boundaries_path, \"w\", **profile_boundary) as dst:\n",
    "            dst.write(boundaries, 1)\n",
    "        print(f\"‚úì Boundaries: {boundaries_path}\")\n",
    "    \n",
    "    if SAVE_GEOJSON:\n",
    "        save_geojson(polygons, polygons_geojson, crs)\n",
    "    \n",
    "    # Visualize\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GENERATING VISUALIZATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    real_image = load_real_image(IMAGE_PATH)\n",
    "    visualize_results(instance_mask, boundaries, polygons, \"polygons_visualization.png\",real_image=real_image)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úì COMPLETE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nOutput files:\")\n",
    "    print(f\"  1. {clean_mask_path} - Filtered instance mask\")\n",
    "    print(f\"  2. {boundaries_path} - Boundaries\")\n",
    "    print(f\"  3. {polygons_geojson} - Polygons (GeoJSON) ‚Üê USE THIS!\")\n",
    "    print(f\"  4. polygons_visualization.png - Visualization\")\n",
    "    \n",
    "    print(f\"\\n‚úì Processing applied:\")\n",
    "    if USE_WATERSHED_SEPARATION:\n",
    "        print(f\"  ‚Ä¢ Watershed separation: separated touching objects\")\n",
    "    if USE_MORPHOLOGY:\n",
    "        print(f\"  ‚Ä¢ Morphological processing: filled holes and smoothed edges\")\n",
    "    print(f\"  ‚Ä¢ Quality filtering: removed small/irregular shapes\")\n",
    "    print(f\"\\n‚úì Only high-quality objects with proper shapes!\")\n",
    "    \n",
    "    return instance_mask, boundaries, polygons,real_image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        instance_mask, boundaries, polygons,real_image = main()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d938d-d104-4953-b3f1-137747559130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from samgeo import SamGeo2\n",
    "import cv2\n",
    "\n",
    "# Initialize SAM\n",
    "sam2 = SamGeo2(\n",
    "    model_id=\"sam2-hiera-large\",\n",
    "    apply_postprocessing=True,\n",
    "    points_per_side=64,        \n",
    "    points_per_batch=128,\n",
    "    pred_iou_thresh=0.5,         \n",
    "    stability_score_thresh=0.5,\n",
    "    stability_score_offset=0.0,\n",
    "    crop_n_layers=1,          \n",
    "    box_nms_thresh=0.8,\n",
    "    min_mask_region_area=10.0,   \n",
    "    use_m2m=True,              \n",
    ")\n",
    "\n",
    "def overlay_mask_downsampled(image_path, output_dir=\"outputs2\", max_size=1024, alpha=0.4, overlay_boundaries=True):\n",
    "    \"\"\"\n",
    "    Overlay instance mask on a downsampled original image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        Path to the original image.\n",
    "    output_dir : str\n",
    "        Directory to save intermediate outputs.\n",
    "    max_size : int\n",
    "        Maximum width or height for visualization.\n",
    "    alpha : float\n",
    "        Transparency for overlay.\n",
    "    overlay_boundaries : bool\n",
    "        Whether to overlay boundaries in red.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    mask_path = os.path.join(output_dir, f\"{base_name}_masks.tif\")\n",
    "    \n",
    "    # Generate SAM masks\n",
    "    sam2.generate(image_path)\n",
    "    sam2.save_masks(mask_path)\n",
    "    sam2.show_anns(\n",
    "    axis=\"off\",\n",
    "    alpha=0.7)\n",
    "    # Run your main pipeline to get instance mask\n",
    "    try:\n",
    "        instance_mask, boundaries, polygons = main(mask_path)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {mask_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "    # Open original image\n",
    "    with rasterio.open(image_path) as src:\n",
    "        img = src.read([1, 2, 3])  # Assuming RGB\n",
    "        img = img.transpose(1, 2, 0).astype(float)  # H x W x C\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # Normalize to 0-1\n",
    "\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        scale = min(max_size / orig_w, max_size / orig_h, 1.0)\n",
    "\n",
    "        if scale < 1.0:\n",
    "            new_w, new_h = int(orig_w * scale), int(orig_h * scale)\n",
    "            img_ds = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            mask_ds = cv2.resize(instance_mask.astype(np.float32), (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "            boundaries_ds = cv2.resize(boundaries.astype(np.uint8), (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            img_ds = img\n",
    "            mask_ds = instance_mask\n",
    "            boundaries_ds = boundaries\n",
    "\n",
    "        # Create colored overlay\n",
    "        num_objects = int(np.max(mask_ds))  # Fix TypeError by casting to int\n",
    "        if num_objects == 0:\n",
    "            overlay = img_ds\n",
    "        else:\n",
    "            import matplotlib.cm as cm\n",
    "            colors = cm.nipy_spectral(np.linspace(0, 1, num_objects + 1))[:, :3]  # RGB only\n",
    "            mask_rgb = colors[mask_ds.astype(int)]\n",
    "            overlay = (1 - alpha) * img_ds + alpha * mask_rgb\n",
    "\n",
    "        # Overlay boundaries if requested\n",
    "        if overlay_boundaries:\n",
    "            overlay[boundaries_ds > 0] = [1.0, 0, 0]  # Red boundaries\n",
    "\n",
    "        # Plot and save\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(overlay)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"{base_name}: {num_objects} objects\")\n",
    "        save_path = os.path.join(output_dir, f\"{base_name}_overlay.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"Overlay saved: {save_path}\")\n",
    "\n",
    "    return {\n",
    "        \"image_path\": image_path,\n",
    "        \"mask_path\": mask_path,\n",
    "        \"overlay_path\": save_path,\n",
    "        \"num_objects\": num_objects\n",
    "    }\n",
    "\n",
    "\n",
    "# ---- Main loop ----\n",
    "image_folder = \"new_test_images\"\n",
    "results = []\n",
    "\n",
    "for file in sorted(os.listdir(image_folder)):\n",
    "    if file.lower().endswith(\".png\"):\n",
    "        full_path = os.path.join(image_folder, file)\n",
    "        print(f\"Processing {full_path} ...\")\n",
    "        res = overlay_mask_downsampled(full_path)\n",
    "        if res:\n",
    "            results.append(res)\n",
    "\n",
    "print(\"All images processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3fef6-bd96-4e88-95cc-7dc56b83f1af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b1931e-4076-4b97-bf4a-4e8d8ebb2e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kill -9 968288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b74f5-7f52-4b26-afb2-b99ce68f7f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Geosam)",
   "language": "python",
   "name": "geosam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
