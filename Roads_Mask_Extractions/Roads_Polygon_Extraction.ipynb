{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cd211-fb8a-48f0-a538-7f52d74e061c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!hf auth login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab2e66c-9618-45d7-802e-f18308840e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f09c22c3f5946b4b0c3acfce5785941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"mask-generation\", model=\"facebook/sam3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd021be2-e900-4fc7-9d3f-3bf7649c8359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "# from transformers import Sam3Model, Sam3Processor\n",
    "\n",
    "\n",
    "# IMAGE_PATH = \"roads/tile_10240_57344.tif\"\n",
    "# TEXT_PROMPT = \"road\"\n",
    "\n",
    "# SCORE_THRESHOLD = 0.55  # instance confidence\n",
    "# MASK_THRESHOLD = 0.40   # pixel threshold\n",
    "\n",
    "\n",
    "# def load_model():\n",
    "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     model = Sam3Model.from_pretrained(\n",
    "#         \"facebook/sam3\",\n",
    "#         torch_dtype=torch.bfloat16\n",
    "#     ).to(device)\n",
    "#     processor = Sam3Processor.from_pretrained(\"facebook/sam3\")\n",
    "#     return model, processor, device\n",
    "\n",
    "# def visualize(image, results):\n",
    "#     overlay = image.convert(\"RGBA\")\n",
    "#     masks = results[\"masks\"].float().cpu().numpy()\n",
    "#     boxes = results[\"boxes\"].float().cpu().numpy()\n",
    "\n",
    "#     if len(masks) == 0:\n",
    "#         return overlay.convert(\"RGB\")\n",
    "\n",
    "#     cmap = plt.cm.plasma\n",
    "#     draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "#     try:\n",
    "#         font = ImageFont.truetype(\"arial.ttf\", 14)\n",
    "#     except:\n",
    "#         font = ImageFont.load_default()\n",
    "\n",
    "#     for i, mask in enumerate(masks):\n",
    "#         color = tuple(int(c * 255) for c in cmap(i / len(masks))[:3])\n",
    "#         layer = Image.new(\"RGBA\", image.size, color + (0,))\n",
    "#         m = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "#         layer.putalpha(m.point(lambda x: 80 if x > 0 else 0))\n",
    "#         overlay = Image.alpha_composite(overlay, layer)\n",
    "\n",
    "#         x1, y1, x2, y2 = boxes[i]\n",
    "#         label = f\"road_{i+1}\"\n",
    "#         draw.rectangle(draw.textbbox((x1, y1), label, font=font), fill=\"black\")\n",
    "#         draw.text((x1, y1), label, fill=\"white\", font=font)\n",
    "\n",
    "#     return overlay.convert(\"RGB\")\n",
    "\n",
    "# def main():\n",
    "#     model, processor, device = load_model()\n",
    "\n",
    "#     image = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "\n",
    "#     inputs = processor(\n",
    "#         images=image,\n",
    "#         text=TEXT_PROMPT,\n",
    "#         return_tensors=\"pt\"\n",
    "#     ).to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     results = processor.post_process_instance_segmentation(\n",
    "#         outputs,\n",
    "#         threshold=SCORE_THRESHOLD,\n",
    "#         mask_threshold=MASK_THRESHOLD,\n",
    "#         target_sizes=inputs[\"original_sizes\"].tolist()\n",
    "#     )[0]\n",
    "\n",
    "#     vis = visualize(image, results)\n",
    "\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(\"Original\")\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(vis)\n",
    "#     plt.title(\"Road Segmentation (No Filtering)\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fb8e9-938c-4019-a158-e021728cb45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Complete Road Segmentation Pipeline with SAM3\n",
    "Segments roads from images and exports to GeoJSON with unique IDs\n",
    "Includes enhanced post-processing: smoothing and strengthening\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, mapping\n",
    "from skimage.morphology import skeletonize\n",
    "from transformers import Sam3Model, Sam3Processor\n",
    "\n",
    "\n",
    "# PART 1: SAM3 MODEL AND SEGMENTATION\n",
    "\n",
    "\n",
    "def load_sam3():\n",
    "    \"\"\"Load SAM3 model\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        model = Sam3Model.from_pretrained(\n",
    "            \"facebook/sam3\",\n",
    "            torch_dtype=torch.bfloat16\n",
    "        ).to(device)\n",
    "        processor = Sam3Processor.from_pretrained(\"facebook/sam3\")\n",
    "        model.eval()\n",
    "        return model, processor, device\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SAM3 model: {e}\")\n",
    "        raise\n",
    "\n",
    "def sam3_to_instance_mask(masks):\n",
    "    \"\"\"\n",
    "    Convert SAM3 masks to instance segmentation mask\n",
    "    masks: (N,H,W) tensor\n",
    "    returns: (H,W) uint16 instance mask\n",
    "    \"\"\"\n",
    "    if len(masks) == 0:\n",
    "        return None\n",
    "    \n",
    "    masks = masks.float().cpu().numpy()\n",
    "    h, w = masks.shape[1:]\n",
    "    instance_mask = np.zeros((h, w), dtype=np.uint16)\n",
    "    \n",
    "    # Assign each mask a unique ID\n",
    "    for i, m in enumerate(masks, start=1):\n",
    "        instance_mask[m > 0.5] = i\n",
    "    \n",
    "    return instance_mask\n",
    "\n",
    "\n",
    "# PART 2: MASK POST-PROCESSING\n",
    "\n",
    "\n",
    "def postprocess_mask(instance_mask, smooth_iterations=4, close_kernel_size=9, open_kernel_size=3):\n",
    "    \"\"\"\n",
    "    Post-process instance mask to smooth and strengthen road segments\n",
    "    Enhanced version with slightly better smoothing\n",
    "    \n",
    "    Args:\n",
    "        instance_mask: (H,W) uint16 instance segmentation mask\n",
    "        smooth_iterations: Number of morphological closing iterations\n",
    "        close_kernel_size: Kernel size for closing (fills gaps)\n",
    "        open_kernel_size: Kernel size for opening (removes noise)\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned instance mask\n",
    "    \"\"\"\n",
    "    print(f\"  Post-processing mask...\")\n",
    "    print(f\"    Original objects: {len(np.unique(instance_mask)) - 1}\")\n",
    "    \n",
    "    # Process each object separately\n",
    "    cleaned_mask = np.zeros_like(instance_mask)\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    valid_id = 1\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        # Extract single object\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        \n",
    "        # Morphological closing (fill gaps, smooth boundaries) - enhanced\n",
    "        close_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (close_kernel_size, close_kernel_size))\n",
    "        for _ in range(smooth_iterations):\n",
    "            obj_mask = cv2.morphologyEx(obj_mask, cv2.MORPH_CLOSE, close_kernel)\n",
    "        \n",
    "        # Morphological opening (remove small noise)\n",
    "        open_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (open_kernel_size, open_kernel_size))\n",
    "        obj_mask = cv2.morphologyEx(obj_mask, cv2.MORPH_OPEN, open_kernel)\n",
    "        \n",
    "        # Enhanced Gaussian blur + threshold for smoother edges\n",
    "        obj_mask_float = obj_mask.astype(np.float32)\n",
    "        obj_mask_float = cv2.GaussianBlur(obj_mask_float, (7, 7), 1.5)\n",
    "        obj_mask = (obj_mask_float > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Additional light smoothing pass\n",
    "        obj_mask_float = obj_mask.astype(np.float32)\n",
    "        obj_mask_float = cv2.GaussianBlur(obj_mask_float, (5, 5), 0.8)\n",
    "        obj_mask = (obj_mask_float > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Assign to cleaned mask if still valid\n",
    "        if np.any(obj_mask):\n",
    "            cleaned_mask[obj_mask > 0] = valid_id\n",
    "            valid_id += 1\n",
    "    \n",
    "    print(f\"    After smoothing: {len(np.unique(cleaned_mask)) - 1} objects\")\n",
    "    \n",
    "    return cleaned_mask\n",
    "\n",
    "\n",
    "def process_image_sam3(\n",
    "    image_path,\n",
    "    model,\n",
    "    processor,\n",
    "    device,\n",
    "    text_prompt,\n",
    "    output_dir,\n",
    "    score_threshold=0.55,\n",
    "    mask_threshold=0.40\n",
    "):\n",
    "    \"\"\"Process single image with SAM3 and save instance mask\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        print(f\"  Image size: {image.size}\")\n",
    "        \n",
    "        # Prepare inputs (SAM3 style)\n",
    "        inputs = processor(\n",
    "            images=image,\n",
    "            text=text_prompt,  # Direct text, not list\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Post-process with SAM3 parameters\n",
    "        results = processor.post_process_instance_segmentation(\n",
    "            outputs,\n",
    "            threshold=score_threshold,       # instance confidence\n",
    "            mask_threshold=mask_threshold,   # pixel threshold\n",
    "            target_sizes=inputs[\"original_sizes\"].tolist()\n",
    "        )[0]\n",
    "        \n",
    "        # Check if masks found\n",
    "        if \"masks\" not in results or len(results[\"masks\"]) == 0:\n",
    "            print(f\"  No objects found\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"  Found {len(results['masks'])} road segments\")\n",
    "        \n",
    "        # Create instance mask\n",
    "        instance_mask = sam3_to_instance_mask(results[\"masks\"])\n",
    "        \n",
    "        if instance_mask is None:\n",
    "            print(f\"  Failed to create instance mask\")\n",
    "            return None\n",
    "        \n",
    "        # Get georeferencing from original image if available\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                transform = src.transform\n",
    "                crs = src.crs\n",
    "        except:\n",
    "            # Create identity transform if no georeference\n",
    "            h, w = instance_mask.shape\n",
    "            transform = rasterio.transform.from_bounds(0, 0, w, h, w, h)\n",
    "            crs = None\n",
    "        \n",
    "        # ===== POST-PROCESSING =====\n",
    "        print(f\"\\n  === Post-Processing ===\")\n",
    "        \n",
    "        # Enhanced smooth and strengthen mask\n",
    "        instance_mask = postprocess_mask(\n",
    "            instance_mask,\n",
    "            smooth_iterations=3,\n",
    "            close_kernel_size=7,\n",
    "            open_kernel_size=3\n",
    "        )\n",
    "        \n",
    "        final_count = len(np.unique(instance_mask)) - 1\n",
    "        print(f\"  Final segments: {final_count}\")\n",
    "        \n",
    "        if final_count == 0:\n",
    "            print(f\"  No valid road segments after post-processing\")\n",
    "            return None\n",
    "        \n",
    "        # Save mask as GeoTIFF\n",
    "        mask_path = os.path.join(output_dir, f\"{base}_instance_mask.tif\")\n",
    "        with rasterio.open(\n",
    "            mask_path,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=instance_mask.shape[0],\n",
    "            width=instance_mask.shape[1],\n",
    "            count=1,\n",
    "            dtype=instance_mask.dtype,\n",
    "            transform=transform,\n",
    "            crs=crs,\n",
    "            compress='lzw'\n",
    "        ) as dst:\n",
    "            dst.write(instance_mask, 1)\n",
    "        \n",
    "        print(f\"  Saved mask: {mask_path}\")\n",
    "        \n",
    "        return {\n",
    "            \"image\": image_path,\n",
    "            \"mask\": mask_path,\n",
    "            \"num_objects\": int(instance_mask.max())\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {image_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# PART 3: POLYGON EXTRACTION AND METRICS\n",
    "\n",
    "\n",
    "def calculate_road_metrics(obj_mask):\n",
    "    \"\"\"Calculate geometric metrics for road segments\"\"\"\n",
    "    try:\n",
    "        contours, _ = cv2.findContours(\n",
    "            obj_mask, \n",
    "            cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        \n",
    "        if not contours:\n",
    "            return None\n",
    "        \n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Fit minimum area rectangle\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        (_, _), (w, h), _ = rect\n",
    "        \n",
    "        length = max(w, h)\n",
    "        width = min(w, h)\n",
    "        \n",
    "        # Calculate skeleton length\n",
    "        skeleton = skeletonize(obj_mask > 0)\n",
    "        skeleton_length = np.sum(skeleton)\n",
    "        \n",
    "        # Metrics\n",
    "        aspect_ratio = length / width if width > 0 else 0\n",
    "        area = np.count_nonzero(obj_mask)\n",
    "        elongation = skeleton_length / np.sqrt(area) if area > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'length': length,\n",
    "            'width': width,\n",
    "            'aspect_ratio': aspect_ratio,\n",
    "            'elongation': elongation,\n",
    "            'skeleton_length': skeleton_length,\n",
    "            'length_width_ratio': aspect_ratio\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"    Warning: Metric calculation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_polygons_per_object(instance_mask, transform, global_id_offset=0, image_name=None):\n",
    "    \"\"\"\n",
    "    Extract polygons from instance mask with globally unique IDs\n",
    "    \"\"\"\n",
    "    unique_ids = np.unique(instance_mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    polygons = []\n",
    "    \n",
    "    for inst_id in unique_ids:\n",
    "        obj_mask = (instance_mask == inst_id).astype(np.uint8)\n",
    "        area = np.count_nonzero(obj_mask)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_road_metrics(obj_mask)\n",
    "        \n",
    "        # Extract polygon geometry\n",
    "        for geom, val in shapes(obj_mask, mask=obj_mask, transform=transform):\n",
    "            if val > 0:\n",
    "                global_id = global_id_offset + int(inst_id)\n",
    "                \n",
    "                poly_data = {\n",
    "                    'polygon': shape(geom),\n",
    "                    'global_id': global_id,\n",
    "                    'local_id': int(inst_id),\n",
    "                    'area_pixels': int(area)\n",
    "                }\n",
    "                \n",
    "                if image_name:\n",
    "                    poly_data['source_image'] = image_name\n",
    "                \n",
    "                if metrics:\n",
    "                    poly_data.update({\n",
    "                        'length_pixels': float(metrics['length']),\n",
    "                        'width_pixels': float(metrics['width']),\n",
    "                        'aspect_ratio': float(metrics['aspect_ratio']),\n",
    "                        'elongation': float(metrics['elongation']),\n",
    "                        'skeleton_length': float(metrics['skeleton_length']),\n",
    "                        'length_width_ratio': float(metrics['length_width_ratio'])\n",
    "                    })\n",
    "                \n",
    "                polygons.append(poly_data)\n",
    "                break\n",
    "    \n",
    "    return polygons\n",
    "\n",
    "def process_mask_to_polygons(mask_path, global_id_offset=0):\n",
    "    \"\"\"Process a single mask file and extract polygons\"\"\"\n",
    "    try:\n",
    "        with rasterio.open(mask_path) as src:\n",
    "            instance_mask = src.read(1)\n",
    "            transform = src.transform\n",
    "            crs = src.crs\n",
    "        \n",
    "        # Get image name from mask filename\n",
    "        image_name = os.path.basename(mask_path).replace('_instance_mask.tif', '')\n",
    "        \n",
    "        print(f\"  Processing: {os.path.basename(mask_path)}\")\n",
    "        print(f\"    Objects: {len(np.unique(instance_mask)) - 1}\")\n",
    "        print(f\"    ID offset: {global_id_offset}\")\n",
    "        \n",
    "        # Extract polygons\n",
    "        polygons = extract_polygons_per_object(\n",
    "            instance_mask, \n",
    "            transform, \n",
    "            global_id_offset,\n",
    "            image_name\n",
    "        )\n",
    "        \n",
    "        max_local_id = int(instance_mask.max())\n",
    "        next_offset = global_id_offset + max_local_id + 1\n",
    "        \n",
    "        print(f\"    Extracted {len(polygons)} polygons\")\n",
    "        print(f\"    ID range: {global_id_offset + 1} to {global_id_offset + max_local_id}\")\n",
    "        \n",
    "        return polygons, next_offset, crs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {mask_path}: {e}\")\n",
    "        return [], global_id_offset, None\n",
    "\n",
    "def save_combined_geojson(all_polygons, output_path, crs=None):\n",
    "    \"\"\"Save all polygons to a single GeoJSON file\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for p in all_polygons:\n",
    "        properties = {\n",
    "            \"id\": p['global_id'],\n",
    "            \"local_id\": p['local_id'],\n",
    "            \"area_pixels\": p['area_pixels']\n",
    "        }\n",
    "        \n",
    "        if 'source_image' in p:\n",
    "            properties['source_image'] = p['source_image']\n",
    "        \n",
    "        if 'length_pixels' in p:\n",
    "            properties.update({\n",
    "                'length_pixels': p['length_pixels'],\n",
    "                'width_pixels': p['width_pixels'],\n",
    "                'aspect_ratio': p['aspect_ratio'],\n",
    "                'elongation': p['elongation'],\n",
    "                'skeleton_length': p['skeleton_length'],\n",
    "                'length_width_ratio': p['length_width_ratio']\n",
    "            })\n",
    "        \n",
    "        features.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": properties,\n",
    "            \"geometry\": mapping(p['polygon'])\n",
    "        })\n",
    "    \n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"crs\": {\n",
    "            \"type\": \"name\", \n",
    "            \"properties\": {\n",
    "                \"name\": str(crs) if crs else \"EPSG:4326\"\n",
    "            }\n",
    "        },\n",
    "        \"features\": features\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(geojson, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✓ Combined GeoJSON saved: {output_path}\")\n",
    "    print(f\"  Total features: {len(features)}\")\n",
    "\n",
    "\n",
    "# PART 4: COMPLETE PIPELINE\n",
    "\n",
    "\n",
    "def run_complete_pipeline(\n",
    "    input_folder=\"roads\",\n",
    "    output_mask_folder=\"outputs_sam3\",\n",
    "    output_geojson=\"all_roads_combined.geojson\",\n",
    "    text_prompt=\"road\",\n",
    "    score_threshold=0.55,\n",
    "    mask_threshold=0.40\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete pipeline: Segment images → Post-process → Extract polygons → Save GeoJSON\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"COMPLETE ROAD SEGMENTATION PIPELINE WITH SAM3\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # STEP 1: LOAD MODEL\n",
    "    print(\"\\n[STEP 1] Loading SAM3 Model...\")\n",
    "    try:\n",
    "        model, processor, device = load_sam3()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check input folder\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Error: Folder '{input_folder}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(input_folder) \n",
    "        if f.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png'))\n",
    "    ])\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in '{input_folder}'\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n[STEP 2] Segmenting {len(image_files)} images...\")\n",
    "    print(f\"Parameters: score_threshold={score_threshold}, mask_threshold={mask_threshold}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    results = []\n",
    "    for i, file in enumerate(image_files, 1):\n",
    "        path = os.path.join(input_folder, file)\n",
    "        print(f\"\\n[{i}/{len(image_files)}] {file}\")\n",
    "        \n",
    "        res = process_image_sam3(\n",
    "            path,\n",
    "            model,\n",
    "            processor,\n",
    "            device,\n",
    "            text_prompt=text_prompt,\n",
    "            output_dir=output_mask_folder,\n",
    "            score_threshold=score_threshold,\n",
    "            mask_threshold=mask_threshold\n",
    "        )\n",
    "        \n",
    "        if res:\n",
    "            results.append(res)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"\\nNo objects detected in any images!\")\n",
    "        return\n",
    "    \n",
    "    # STEP 3: POLYGON EXTRACTION\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"[STEP 3] Extracting Polygons from Masks...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Get all mask files\n",
    "    mask_files = sorted([\n",
    "        f for f in os.listdir(output_mask_folder)\n",
    "        if f.endswith('_instance_mask.tif')\n",
    "    ])\n",
    "    \n",
    "    all_polygons = []\n",
    "    global_id_offset = 0\n",
    "    crs = None\n",
    "    \n",
    "    for i, mask_file in enumerate(mask_files, 1):\n",
    "        mask_path = os.path.join(output_mask_folder, mask_file)\n",
    "        print(f\"\\n[{i}/{len(mask_files)}] {mask_file}\")\n",
    "        \n",
    "        polygons, next_offset, mask_crs = process_mask_to_polygons(\n",
    "            mask_path,\n",
    "            global_id_offset\n",
    "        )\n",
    "        \n",
    "        if mask_crs and not crs:\n",
    "            crs = mask_crs\n",
    "        \n",
    "        all_polygons.extend(polygons)\n",
    "        global_id_offset = next_offset\n",
    "    \n",
    "    # STEP 4: SAVE GEOJSON\n",
    "    if all_polygons:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"[STEP 4] Saving Combined GeoJSON...\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        save_combined_geojson(all_polygons, output_geojson, crs)\n",
    "    \n",
    "    # FINAL SUMMARY\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PIPELINE COMPLETE - SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Input images:           {len(image_files)}\")\n",
    "    print(f\"Successfully segmented: {len(results)}\")\n",
    "    print(f\"Mask files created:     {len(mask_files)}\")\n",
    "    print(f\"Total polygons:         {len(all_polygons)}\")\n",
    "    if all_polygons:\n",
    "        total_objects = sum(r['num_objects'] for r in results)\n",
    "        print(f\"Total road segments:    {total_objects}\")\n",
    "        print(f\"Average per image:      {total_objects/len(results):.1f}\")\n",
    "        print(f\"Global ID range:        1 to {global_id_offset - 1}\")\n",
    "    print(f\"\\nOutput GeoJSON:         {output_geojson}\")\n",
    "    print(f\"Output masks folder:    {output_mask_folder}/\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "# MAIN EXECUTION\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete pipeline with SAM3 parameters\n",
    "    run_complete_pipeline(\n",
    "        input_folder=\"roads\",                          # Input images\n",
    "        output_mask_folder=\"outputs_sam3\",             # Mask output\n",
    "        output_geojson=\"all_roads_combined.geojson\",   # Final GeoJSON\n",
    "        text_prompt=\"road\",                            # Text prompt\n",
    "        score_threshold=0.60,                          # Instance confidence\n",
    "        mask_threshold=0.42                            # Pixel threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7232cce-cac7-4c83-bb04-062ca67e1523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize original images and their instance masks side by side\n",
    "Handles large images (2048x2048) with automatic resizing\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import cv2\n",
    "\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    \"\"\"Load image and corresponding mask\"\"\"\n",
    "    # Load original image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Load instance mask\n",
    "    with rasterio.open(mask_path) as src:\n",
    "        mask = src.read(1)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def resize_if_needed(img, mask, max_size=1024):\n",
    "    \"\"\"\n",
    "    Resize image and mask if larger than max_size\n",
    "    Maintains aspect ratio\n",
    "    \"\"\"\n",
    "    img_array = np.array(img)\n",
    "    h, w = img_array.shape[:2]\n",
    "    \n",
    "    # Check if resizing needed\n",
    "    if h <= max_size and w <= max_size:\n",
    "        return img, mask\n",
    "    \n",
    "    # Calculate scale\n",
    "    scale = min(max_size / w, max_size / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    \n",
    "    print(f\"  Resizing from {w}x{h} to {new_w}x{new_h}\")\n",
    "    \n",
    "    # Resize image\n",
    "    img_resized = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "    \n",
    "    # Resize mask (using nearest neighbor to preserve instance IDs)\n",
    "    mask_resized = cv2.resize(\n",
    "        mask.astype(np.int32),\n",
    "        (new_w, new_h),\n",
    "        interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "    \n",
    "    return img_resized, mask_resized\n",
    "\n",
    "def create_colored_mask(mask):\n",
    "    \"\"\"\n",
    "    Create RGB colored mask from instance mask\n",
    "    Each instance gets a unique color\n",
    "    \"\"\"\n",
    "    num_instances = int(mask.max())\n",
    "    \n",
    "    if num_instances == 0:\n",
    "        # No instances, return black mask\n",
    "        h, w = mask.shape\n",
    "        return np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Generate colors using colormap\n",
    "    colors = cm.nipy_spectral(np.linspace(0, 1, num_instances + 1))[:, :3]\n",
    "    colors = (colors * 255).astype(np.uint8)\n",
    "    \n",
    "    # Apply colors to mask\n",
    "    colored_mask = colors[mask]\n",
    "    \n",
    "    return colored_mask\n",
    "\n",
    "def visualize_single_pair(image_path, mask_path, max_size=1024, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize single image-mask pair\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to original image\n",
    "        mask_path: Path to instance mask\n",
    "        max_size: Maximum dimension for display (default 1024)\n",
    "        save_path: Optional path to save visualization\n",
    "    \"\"\"\n",
    "    print(f\"Visualizing: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    # Load data\n",
    "    image, mask = load_image_and_mask(image_path, mask_path)\n",
    "    \n",
    "    # Resize if needed\n",
    "    image_display, mask_display = resize_if_needed(image, mask, max_size)\n",
    "    \n",
    "    # Create colored mask\n",
    "    colored_mask = create_colored_mask(mask_display)\n",
    "    \n",
    "    # Get statistics\n",
    "    num_instances = int(mask_display.max())\n",
    "    original_size = image.size\n",
    "    display_size = image_display.size\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(image_display)\n",
    "    axes[0].set_title(f\"Original Image\\nSize: {original_size[0]}x{original_size[1]}\", \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Instance mask\n",
    "    axes[1].imshow(colored_mask)\n",
    "    axes[1].set_title(f\"Instance Mask\\n{num_instances} road segments detected\", \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle(os.path.basename(image_path), fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if requested\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    print()\n",
    "\n",
    "def visualize_multiple_pairs(image_folder, mask_folder, max_size=1024, \n",
    "                             save_dir=None, show_plots=True):\n",
    "    \"\"\"\n",
    "    Visualize multiple image-mask pairs\n",
    "    \n",
    "    Args:\n",
    "        image_folder: Folder containing original images\n",
    "        mask_folder: Folder containing instance masks\n",
    "        max_size: Maximum dimension for display\n",
    "        save_dir: Optional directory to save visualizations\n",
    "        show_plots: Whether to show plots (set False for batch processing)\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"VISUALIZING IMAGE-MASK PAIRS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create save directory if needed\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all images\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(image_folder)\n",
    "        if f.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png'))\n",
    "    ])\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_folder}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(image_files)} images\\n\")\n",
    "    \n",
    "    # Process each image\n",
    "    for i, img_file in enumerate(image_files, 1):\n",
    "        image_path = os.path.join(image_folder, img_file)\n",
    "        \n",
    "        # Find corresponding mask\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        mask_file = f\"{base_name}_instance_mask.tif\"\n",
    "        mask_path = os.path.join(mask_folder, mask_file)\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"[{i}/{len(image_files)}] Skipping {img_file} - no mask found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"[{i}/{len(image_files)}] {img_file}\")\n",
    "        \n",
    "        # Prepare save path\n",
    "        save_path = None\n",
    "        if save_dir:\n",
    "            save_path = os.path.join(save_dir, f\"{base_name}_visualization.png\")\n",
    "        \n",
    "        # Visualize\n",
    "        try:\n",
    "            # Load data\n",
    "            image, mask = load_image_and_mask(image_path, mask_path)\n",
    "            image_display, mask_display = resize_if_needed(image, mask, max_size)\n",
    "            colored_mask = create_colored_mask(mask_display)\n",
    "            \n",
    "            num_instances = int(mask_display.max())\n",
    "            original_size = image.size\n",
    "            \n",
    "            # Create visualization\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            \n",
    "            axes[0].imshow(image_display)\n",
    "            axes[0].set_title(f\"Original Image\\nSize: {original_size[0]}x{original_size[1]}\", \n",
    "                            fontsize=14, fontweight='bold')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            axes[1].imshow(colored_mask)\n",
    "            axes[1].set_title(f\"Instance Mask\\n{num_instances} road segments\", \n",
    "                            fontsize=14, fontweight='bold')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            fig.suptitle(img_file, fontsize=16, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if save_path:\n",
    "                plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "                print(f\"  Saved: {save_path}\")\n",
    "            \n",
    "            if show_plots:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "            \n",
    "            print(f\"  Instances: {num_instances}\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            print()\n",
    "            continue\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"VISUALIZATION COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "def visualize_grid(image_folder, mask_folder, max_images=9, max_size=1024, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize multiple image-mask pairs in a grid\n",
    "    \n",
    "    Args:\n",
    "        image_folder: Folder containing original images\n",
    "        mask_folder: Folder containing instance masks\n",
    "        max_images: Maximum number of images to show in grid\n",
    "        max_size: Maximum dimension for each image\n",
    "        save_path: Optional path to save grid visualization\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"CREATING GRID VISUALIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get all images\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(image_folder)\n",
    "        if f.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png'))\n",
    "    ])[:max_images]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_folder}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate grid size\n",
    "    n_images = len(image_files)\n",
    "    n_cols = min(3, n_images)\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols * 2, figsize=(n_cols * 8, n_rows * 4))\n",
    "    \n",
    "    # Flatten axes for easier indexing\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, img_file in enumerate(image_files):\n",
    "        row = idx // n_cols\n",
    "        col = idx % n_cols\n",
    "        \n",
    "        image_path = os.path.join(image_folder, img_file)\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        mask_path = os.path.join(mask_folder, f\"{base_name}_instance_mask.tif\")\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load and resize\n",
    "            image, mask = load_image_and_mask(image_path, mask_path)\n",
    "            image_display, mask_display = resize_if_needed(image, mask, max_size)\n",
    "            colored_mask = create_colored_mask(mask_display)\n",
    "            \n",
    "            # Plot image\n",
    "            ax_img = axes[row, col * 2]\n",
    "            ax_img.imshow(image_display)\n",
    "            ax_img.set_title(f\"{base_name}\\nOriginal\", fontsize=10)\n",
    "            ax_img.axis('off')\n",
    "            \n",
    "            # Plot mask\n",
    "            ax_mask = axes[row, col * 2 + 1]\n",
    "            ax_mask.imshow(colored_mask)\n",
    "            ax_mask.set_title(f\"{int(mask_display.max())} segments\\nMask\", fontsize=10)\n",
    "            ax_mask.axis('off')\n",
    "            \n",
    "            print(f\"Added: {img_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_images, n_rows * n_cols):\n",
    "        row = idx // n_cols\n",
    "        col = idx % n_cols\n",
    "        axes[row, col * 2].axis('off')\n",
    "        axes[row, col * 2 + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nGrid saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "\n",
    "# EXAMPLE USAGE\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # OPTION 2: Visualize all image-mask pairs (one by one)\n",
    "    print(\"\\n### OPTION 2: Multiple Visualizations ###\\n\")\n",
    "    visualize_multiple_pairs(\n",
    "        image_folder=\"roads\",\n",
    "        mask_folder=\"outputs_sam3\",\n",
    "        max_size=1024,\n",
    "        save_dir=\"visualizations\",  # Optional: save all visualizations\n",
    "        show_plots=True  # Set False for batch processing without display\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2104f3-a7cc-4ab8-9987-5ec7bf3b8ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (preprocess)",
   "language": "python",
   "name": "preprocesss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
